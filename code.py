# -*- coding: utf-8 -*-
"""Text_Generation_with_GPT-2(Project_1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DPjB81H0MZFe-IbAyyAoxBYt6Sh5QENb

# Install and Imports
"""

!pip install -q gradio
!pip install -q git+https://github.com/huggingface/transformers.git

import gradio as gr
import tensorflow as tf
from transformers import TFGPT2LMHeadModel, GPT2Tokenizer

!pip install --upgrade gradio

"""# Defining a Memory Structure"""

memory = {
    "internship_company": "Octanet Internship Company",
    "field_of_internship": "Java development"
}

"""# Function to Update and Use Memory"""

def update_memory(key, value):
    memory[key] = value
    return f"Memory updated: {key} is now {value}"

def generate_text(inp):
    input_ids = tokenizer.encode(inp, return_tensors='tf')
    beam_output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)
    output = tokenizer.decode(beam_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)
    return ".".join(output.split(".")[:-1]) + "."

"""# Integrate with Gradio Interface"""

from transformers import GPT2Tokenizer, TFGPT2LMHeadModel

# Load tokenizer and model
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = TFGPT2LMHeadModel.from_pretrained("gpt2", pad_token_id=tokenizer.eos_token_id)

# Define memory
memory = {
    "internship_company": "Octanet Internship Company",
    "field_of_internship": "Java development"
}

# Define functions
def update_memory(key, value):
    memory[key] = value
    return f"Memory updated: {key} is now {value}"

def generate_text(inp):
    input_ids = tokenizer.encode(inp, return_tensors='tf')
    beam_output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)
    output = tokenizer.decode(beam_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)
    return ".".join(output.split(".")[:-1]) + "."

# Create Gradio interface
input_textbox = gr.Textbox(lines=2, placeholder="Enter a sentence...")
memory_key_textbox = gr.Textbox(lines=1, placeholder="Memory key...")
memory_value_textbox = gr.Textbox(lines=1, placeholder="Memory value...")

generate_btn = gr.Button("Generate Text")
update_memory_btn = gr.Button("Update Memory")

generate_text_interface = gr.Interface(fn=generate_text, inputs=input_textbox, outputs=gr.Textbox(), title="GPT-2", description="Generate text using GPT-2.")
update_memory_interface = gr.Interface(fn=update_memory, inputs=[memory_key_textbox, memory_value_textbox], outputs=gr.Textbox(), title="Update Memory", description="Update memory key-value pairs.")

# Launch the interface
gr.TabbedInterface([generate_text_interface, update_memory_interface], tab_names=["Generate Text", "Update Memory"]).launch()